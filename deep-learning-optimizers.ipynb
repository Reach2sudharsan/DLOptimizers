{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-19T23:36:23.068148Z","iopub.execute_input":"2023-12-19T23:36:23.068720Z","iopub.status.idle":"2023-12-19T23:36:23.078372Z","shell.execute_reply.started":"2023-12-19T23:36:23.068683Z","shell.execute_reply":"2023-12-19T23:36:23.076544Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import keras \nimport time\nfrom keras.datasets import mnist \nfrom keras.models import Sequential \nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nimport time\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nprint(x_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T23:36:23.080916Z","iopub.execute_input":"2023-12-19T23:36:23.081425Z","iopub.status.idle":"2023-12-19T23:36:23.415210Z","shell.execute_reply.started":"2023-12-19T23:36:23.081384Z","shell.execute_reply":"2023-12-19T23:36:23.413717Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"(60000, 28, 28) (60000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"x_train= x_train.reshape(x_train.shape[0],28,28,1)\nx_test=  x_test.reshape(x_test.shape[0],28,28,1)\ninput_shape=(28,28,1)\ny_train=keras.utils.to_categorical(y_train)#,num_classes=)\ny_test=keras.utils.to_categorical(y_test)#, num_classes)\nx_train= x_train.astype('float32')\nx_test= x_test.astype('float32')\nx_train /= 255\nx_test /=255","metadata":{"execution":{"iopub.status.busy":"2023-12-19T23:36:23.417103Z","iopub.execute_input":"2023-12-19T23:36:23.417645Z","iopub.status.idle":"2023-12-19T23:36:23.528504Z","shell.execute_reply.started":"2023-12-19T23:36:23.417591Z","shell.execute_reply":"2023-12-19T23:36:23.527273Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch_size=64\n\nnum_classes=10\n\nepochs=10\n\ndef build_model(optimizer):\n\n    model=Sequential()\n\n    model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n\n    model.add(MaxPooling2D(pool_size=(2,2)))\n\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n\n    model.add(Dense(256, activation='relu'))\n\n    model.add(Dropout(0.5))\n\n    model.add(Dense(num_classes, activation='softmax'))\n\n    model.compile(loss=keras.losses.MeanSquaredError(), optimizer= optimizer, metrics=['accuracy'])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-19T23:36:23.530847Z","iopub.execute_input":"2023-12-19T23:36:23.531252Z","iopub.status.idle":"2023-12-19T23:36:23.541277Z","shell.execute_reply.started":"2023-12-19T23:36:23.531217Z","shell.execute_reply":"2023-12-19T23:36:23.539910Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"optimizers = ['Adadelta', 'Adagrad', 'Adam', 'RMSprop', 'SGD',SGD_momentum,SGD_nesterov]\n\nSGD_momentum = keras.optimizers.SGD(\n    learning_rate=0.01,\n    momentum=0.9,\n    nesterov=False,\n    weight_decay=None,\n    clipnorm=None,\n    clipvalue=None,\n    global_clipnorm=None,\n    use_ema=False,\n    ema_momentum=0.99,\n    ema_overwrite_frequency=None,\n    name=\"SGD\",\n    **kwargs\n)\n\nSGD_nesterov = keras.optimizers.SGD(    \n    learning_rate=0.01,\n    momentum=0.0,\n    nesterov=True,\n    weight_decay=None,\n    clipnorm=None,\n    clipvalue=None,\n    global_clipnorm=None,\n    use_ema=False,\n    ema_momentum=0.99,\n    ema_overwrite_frequency=None,\n    name=\"SGD\",\n    **kwargs\n)\n\n\nfor i in optimizers:\n    start_time = time.perf_counter()\n    model = build_model(i)\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n    loss,accuracy = model.evaluate(x_test,y_test)\n    end_time = time.perf_counter()\n    print(f\"Accuracy of {i} is: {accuracy}\")\n    print(f\"Loss of {i} is: {loss}\")\n    print(f\"Time of {i} is: {end_time-start_time}\")\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-19T23:36:23.542918Z","iopub.execute_input":"2023-12-19T23:36:23.543316Z","iopub.status.idle":"2023-12-19T23:55:50.060981Z","shell.execute_reply.started":"2023-12-19T23:36:23.543284Z","shell.execute_reply":"2023-12-19T23:55:50.059880Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/10\n938/938 [==============================] - 26s 27ms/step - loss: 0.0900 - accuracy: 0.1100\nEpoch 2/10\n938/938 [==============================] - 25s 26ms/step - loss: 0.0898 - accuracy: 0.1160\nEpoch 3/10\n938/938 [==============================] - 25s 26ms/step - loss: 0.0896 - accuracy: 0.1286\nEpoch 4/10\n938/938 [==============================] - 25s 26ms/step - loss: 0.0895 - accuracy: 0.1336\nEpoch 5/10\n938/938 [==============================] - 25s 27ms/step - loss: 0.0893 - accuracy: 0.1443\nEpoch 6/10\n938/938 [==============================] - 25s 27ms/step - loss: 0.0892 - accuracy: 0.1520\nEpoch 7/10\n938/938 [==============================] - 25s 26ms/step - loss: 0.0890 - accuracy: 0.1637\nEpoch 8/10\n938/938 [==============================] - 25s 27ms/step - loss: 0.0889 - accuracy: 0.1722\nEpoch 9/10\n938/938 [==============================] - 25s 27ms/step - loss: 0.0887 - accuracy: 0.1851\nEpoch 10/10\n938/938 [==============================] - 25s 27ms/step - loss: 0.0885 - accuracy: 0.1961\n313/313 [==============================] - 2s 5ms/step - loss: 0.0880 - accuracy: 0.2762\nAccuracy of Adadelta is: 0.27619999647140503\nLoss of Adadelta is: 0.08796146512031555\nTime of Adadelta is: 251.8747881690001\nEpoch 1/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0903 - accuracy: 0.1078\nEpoch 2/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0899 - accuracy: 0.1290\nEpoch 3/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0895 - accuracy: 0.1549\nEpoch 4/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0891 - accuracy: 0.1868\nEpoch 5/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0887 - accuracy: 0.2157\nEpoch 6/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0883 - accuracy: 0.2554\nEpoch 7/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0877 - accuracy: 0.2948\nEpoch 8/10\n938/938 [==============================] - 21s 23ms/step - loss: 0.0871 - accuracy: 0.3356\nEpoch 9/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0864 - accuracy: 0.3658\nEpoch 10/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0855 - accuracy: 0.3999\n313/313 [==============================] - 2s 5ms/step - loss: 0.0841 - accuracy: 0.5931\nAccuracy of Adagrad is: 0.5931000113487244\nLoss of Adagrad is: 0.08406943082809448\nTime of Adagrad is: 221.12708817799967\nEpoch 1/10\n938/938 [==============================] - 24s 25ms/step - loss: 0.0109 - accuracy: 0.9283\nEpoch 2/10\n938/938 [==============================] - 23s 25ms/step - loss: 0.0046 - accuracy: 0.9704\nEpoch 3/10\n938/938 [==============================] - 23s 25ms/step - loss: 0.0035 - accuracy: 0.9779\nEpoch 4/10\n938/938 [==============================] - 23s 25ms/step - loss: 0.0030 - accuracy: 0.9811\nEpoch 5/10\n938/938 [==============================] - 23s 24ms/step - loss: 0.0025 - accuracy: 0.9839\nEpoch 6/10\n938/938 [==============================] - 23s 25ms/step - loss: 0.0023 - accuracy: 0.9855\nEpoch 7/10\n938/938 [==============================] - 23s 25ms/step - loss: 0.0021 - accuracy: 0.9871\nEpoch 8/10\n938/938 [==============================] - 23s 25ms/step - loss: 0.0020 - accuracy: 0.9876\nEpoch 9/10\n938/938 [==============================] - 23s 25ms/step - loss: 0.0017 - accuracy: 0.9894\nEpoch 10/10\n938/938 [==============================] - 23s 25ms/step - loss: 0.0017 - accuracy: 0.9888\n313/313 [==============================] - 2s 5ms/step - loss: 0.0017 - accuracy: 0.9880\nAccuracy of Adam is: 0.9879999756813049\nLoss of Adam is: 0.0017116590170189738\nTime of Adam is: 265.1393212130006\nEpoch 1/10\n938/938 [==============================] - 23s 24ms/step - loss: 0.0177 - accuracy: 0.8803\nEpoch 2/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0073 - accuracy: 0.9536\nEpoch 3/10\n938/938 [==============================] - 22s 24ms/step - loss: 0.0053 - accuracy: 0.9664\nEpoch 4/10\n938/938 [==============================] - 22s 24ms/step - loss: 0.0043 - accuracy: 0.9726\nEpoch 5/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0038 - accuracy: 0.9757\nEpoch 6/10\n938/938 [==============================] - 22s 24ms/step - loss: 0.0034 - accuracy: 0.9783\nEpoch 7/10\n938/938 [==============================] - 22s 24ms/step - loss: 0.0030 - accuracy: 0.9809\nEpoch 8/10\n938/938 [==============================] - 22s 23ms/step - loss: 0.0027 - accuracy: 0.9827\nEpoch 9/10\n938/938 [==============================] - 22s 24ms/step - loss: 0.0025 - accuracy: 0.9841\nEpoch 10/10\n938/938 [==============================] - 22s 24ms/step - loss: 0.0023 - accuracy: 0.9852\n313/313 [==============================] - 2s 5ms/step - loss: 0.0020 - accuracy: 0.9860\nAccuracy of RMSprop is: 0.9860000014305115\nLoss of RMSprop is: 0.001964273164048791\nTime of RMSprop is: 223.76356160600062\nEpoch 1/10\n938/938 [==============================] - 21s 21ms/step - loss: 0.0898 - accuracy: 0.1368\nEpoch 2/10\n938/938 [==============================] - 20s 21ms/step - loss: 0.0886 - accuracy: 0.2480\nEpoch 3/10\n938/938 [==============================] - 20s 22ms/step - loss: 0.0869 - accuracy: 0.3626\nEpoch 4/10\n938/938 [==============================] - 20s 21ms/step - loss: 0.0837 - accuracy: 0.4530\nEpoch 5/10\n938/938 [==============================] - 20s 22ms/step - loss: 0.0765 - accuracy: 0.5132\nEpoch 6/10\n938/938 [==============================] - 20s 22ms/step - loss: 0.0642 - accuracy: 0.5782\nEpoch 7/10\n938/938 [==============================] - 20s 21ms/step - loss: 0.0527 - accuracy: 0.6492\nEpoch 8/10\n938/938 [==============================] - 20s 22ms/step - loss: 0.0445 - accuracy: 0.7062\nEpoch 9/10\n938/938 [==============================] - 20s 22ms/step - loss: 0.0387 - accuracy: 0.7454\nEpoch 10/10\n938/938 [==============================] - 20s 21ms/step - loss: 0.0345 - accuracy: 0.7738\n313/313 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.8660\nAccuracy of SGD is: 0.8659999966621399\nLoss of SGD is: 0.023447686806321144\nTime of SGD is: 204.60071601799973\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}